[
            {
                "categoryName" : "Отравление",
                "description" : "Атака Отравления данных — это состязательная атака, которая пытается манипулировать обучающим набором данных с целью управления поведением будущей модели, чтобы она помечала вредоносные примеры как желаемые классы. В результате такой атаки ИИ может начать помечать спам-сообщения как безопасные или некорректно классифицировать определенные изображения."

            },
            {
                "categoryName" : "Исследование",
                "description" : "2"
            },
            {
                "categoryName" : "Искажение",
                "description" : "Атака Искажения (или уклонения) предполагает внесение «шумов» в обученные нейросети в целях нарушения их корректной работы. Добавляя определённый случайный «шум» в исходные данные (такой «шум», т.е. помехи, вносятся, например, в изображения на уровне пикселей, так, что человеческий глаз их не замечает) за счёт изменения, например, весовых коэффициентов анализируемых признаков, можно сделать так, что нейросеть при определённых условиях утратит работоспособность."
            }
        ]