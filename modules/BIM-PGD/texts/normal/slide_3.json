{
    "info": "   Слой активации - передает скалярный результат каждой свёртки на функцию активации.\n   Выбор функции завивит от разработчика, однако в большинстве современных CNN сетей используется функция ReLU (Rectified Linear Unit).\n   По сути ReLU это операция отсечения отрицательной части скалярной величины.\n   Простота этой функции значительно ускоряет процесс классификации.",

    "script": "[+] ACTIVATION LAYER: Analysing layer data...",

    "action": {}
}