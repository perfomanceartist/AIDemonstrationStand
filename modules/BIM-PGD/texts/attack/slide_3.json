{
    "info": "      Слой активации - передает скалярный результат каждой свёртки на функцию активации.\n    Выбор функции завивит от разработчика, однако в большинстве современных CNN сетей используется функция ReLU (Rectified Linear Unit).\n\n  Угроза BIM/PGD ищет минимальное зашумление входного изображения, чтобы заставить CNN сворачивать слои к неверным параметрам.\n   Если состязательный пример выходит за пределы допустимого, то данный метод возвращает состязательный образец обратно.\n   В данной демонстрации зашумленность изображения преувеличена для наглядности, в реальной ситуации оно практически не заметно человеческому взгляду.",

    "script": "[+] ACTIVATION LAYER: Analysing layer data...",

    "action": {}
}