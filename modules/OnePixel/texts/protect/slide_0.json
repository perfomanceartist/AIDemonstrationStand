{
    "info": "Атака искажения (или уклонения) предполагает внесение «шумов» в обученные нейросети в целях нарушения их корректной работы. Добавляя определённый случайный «шум» в исходные данные (такой «шум», т.е. помехи, вносятся, например, в изображения на уровне пикселей, так, что человеческий глаз их не замечает) за счёт изменения, например, весовых коэффициентов анализируемых признаков, можно сделать так, что нейросеть при определённых условиях утратит работоспособность.\nГенеративно-состязательная сеть (GAN) — алгоритм машинного обучения, построенный на комбинации из двух нейронных сетей, одна из которых (сеть G) генерирует образцы，а другая (сеть D) старается отличить правильные («подлинные») образцы от неправильных. Так как сети G и D имеют противоположные цели — создать образцы и отбраковать образцы — между ними возникает антагонистическая игра, которая позволяет модели \"обучать себя\".",

    "script": "   ----------------CIFAR 10 (GAN)-----------------",

    "action": {}
}