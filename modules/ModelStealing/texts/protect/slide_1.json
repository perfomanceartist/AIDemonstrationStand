
{
    "info": "     Ошибка оценки гиперпараметра линейна по отношению к разнице между изученными параметрами модели и минимумом целевой функции, которая ближе всего к ним. Эта теорема подразумевает, что мы могли бы защититься от наших атак на кражу гиперпараметров, увеличив такую разницу. Поэтому мы предлагаем, чтобы алгоритм нейросети округлял изученные параметры модели, прежде чем делиться ими с конечным пользователем.\n      Например, предположим, что параметр модели равен 0,8675342, округление параметра модели до одного десятичного знака и двух десятичных знаков приводит к 0,9 и 0,87 соответственно. Округление параметров модели приводит к потере точности украденных гиперпараметров. В модели алгоритма машинного обучения можно округлить следующее: \n     1. Коэффициенты регрессии w \n     2. Выходные данные",

    "script": "     ---- LASSO ----  ",

    "action": { 
        "Script": "HYPER"
    }
}