{
    "info": "   Distillation for Membership Privacy (DMP, дистилляция знаний для приватности членства) – метод защиты от атак выведения членства, основанный на дистилляции знаний. В машинном обучении дистилляция знаний - это процесс передачи знаний из большой модели в меньшую без потери достоверности.\n    Так как атака выведения членства довольно успешно позволяет устанавливать факт присутствия определенного экземпляра данных в обучающей выборке модели, возникает идея обучить модель на публичных, общедоступных данных. Этот способ защиты не снижает эффективность атаки, однако делает атаку бессмысленной, так как при обучении на публичных данных заявляется, какие данные используются при обучении модели, т.е. с помощью атаки нельзя вывести никаких новых данных.",

    "script": "     ---- Membership Inference Attack  ----  ",

    "action": {
        
    }
}